# Отток клиентов

## Описание проекта

Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

## Данные

Данные находятся в файле /datasets/Churn.csv (англ. «отток клиентов»). Скачать датасет

**Признаки:**
- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — сколько лет человек является клиентом банка
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `sActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

**Целевой признак:**

- `Exited` — факт ухода клиента

## Задача

Cпрогнозировать, уйдёт клиент из банка в ближайшее время или нет.

## Используемые библиотеки
*Pandas*, *Matplotlib*, *Scikit-learn*

## Шаги

1. Подготовка данных
1.1. Кодирование
1.2. Разделение выборки на три части
1.3. Масштабирование
1.4. Разделение выборки на обучающие признаки и целевой
1.5. Выводы
2. Исследование задачи
2.1. Логистическая регрессия
- Метрики
- ROC-кривая
- AUC-ROC
2.1.1. Решающие деревья
2.1.2. Метрики
2.1.3. ROC-кривая
2.1.4. AUC-ROC
2.2. Случайный лес
2.2.1. Метрики
2.2.2. ROC-кривая
2.2.3. AUC-ROC
3. Борьба с дисбалансом
3.1. Уменьшение выборки
3.2. Увеличение выборки
3.3. Выводы:
4. Валидация моделей в балансе
4.1. Способ борьбы с дисбалансом - upsample
4.1.1.  Логистическая регрессия
- Метрики
- ROC-кривая
- AUC-ROC
4.1.2.  Решающие деревья
- Метрики
- ROC-кривая
- AUC-ROC
4.1.3.  Случайный лес
- Метрики
- ROC-кривая
- AUC-ROC
4.2. Способ борьбы с дисбалансом - downsample
4.2.1. Логистическая регрессия
- Метрики
- ROC-кривая
- AUC-ROC
4.2.2. Решающие деревья
- Метрики
- ROC-кривая
- AUC-ROC
4.2.3. Случайный лес
- Метрики
- ROC-кривая
- AUC-ROC
4.3. Выводы
5.  Тестирование модели
5.0.1. Метрики
5.0.2. ROC-кривая
5.0.3. AUC-ROC
5.1  Выводы

## Выводы

Мы загрузили данные и подготовили их, проведя кодирование и масштабирование.

До исправления дисбаланса все модели показывали не самык лучшие результаты.

В выборке наблюдаелся дисбаланс классов. Для исправления дисбаланса классов можно использовать как уменьшение, так и увеличение выборки. Для дальнейшей работы мы использовали уменьшение и увеличение выборки. Послндннн оказалось эффективней.

После балансировки классов, метрики моделей стали намного лучше. Все с уровнем F1-меры значительно выше 0.59.

Наилучшей моделью оказался Случайный лес: с

F1-мера: 0.6006984866123398
