# Определение токсичности комментариев

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Данные

Предоставлены данные о комментариях:
- Текст
- Токсичность

## Задача

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.

## Используемые библиотеки
*Python*, *Pandas*, *BERT*, *nltk*, *tf-idf*

## Шаги

1  Подготовка
1.1  Загрузка данных
1.2  Подготовка признаков
1.2.1  Лемматизация
1.3  Разделение на выборки
1.4  Изменение баланса классов
1.4.1  Изменение весов классов
1.5  Вывод по шагу 1
2  Обучение
2.1  Классификатор LogisticRegression
2.2  Классификатор DecisionTreeClassifier
2.3  Классификатор CatBoostClassifier
2.4  Классификатор SGDClassifier
2.5  Классификатор LightGBM
2.6  Вывод по шагу 2

## Выводы

В ходе работы над проектом было сделано:

- Подготовленны данные обучения на моделях.
- Выбран способ баланса классов и поделены данные на обучающую, валидационную и тестовою выборку.
- Обучены модели и выбраны лучшие из них на валидационной выборке.
- Показаны параметры качества моделей.

Исходные данные обладают большим количеством признаков. Созданных столбцов больше, чем записей данных. Так как TF-IDF превращают текст в численные значения, лучшими моделями стали LogisticRegression, SGDClassifier и LGBMClassifier. CatBoostClassifier может показать себя очень хорошо при долгом обучении на данных. В ходе тестов данный классификатор мог обучатся до 5 часов.

На тестовой выбоке по метрике F1 лучше всего себя показал LGBMClassifier всего на 0.77. Данная модель обладает больними показателями Precision и Accuracy. Это говорит нам, что токсичные комментарии находятся лучше.
